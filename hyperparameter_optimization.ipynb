{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca3be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "522acb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dsname):\n",
    "    metadata = pd.read_csv(f\"/datasets/nicolas_facchinetti/processed_data/{dsname}/metadata_final.csv\")\n",
    "    x = pickle.load(open(f\"/datasets/nicolas_facchinetti/processed_data/{dsname}/processed_data0.p\", \"rb\" ))\n",
    "    y = pickle.load(open(f\"/datasets/nicolas_facchinetti/processed_data/{dsname}/processed_labels.p\", \"rb\" ))\n",
    "    return metadata, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c4a903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def standardize(data):\n",
    "    scaler = StandardScaler()\n",
    "    n = data.shape\n",
    "    return scaler.fit_transform(data.reshape(n[0],-1)).reshape(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c97d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"emodb\", \"emovo\", \"ravdess\"]\n",
    "data = {}\n",
    "for d in datasets:\n",
    "    md, x, y = load_dataset(d)\n",
    "    data[d] = {}\n",
    "    data[d][\"x\"] = standardize(x)\n",
    "    data[d][\"y\"] = y\n",
    "    data[d][\"metadata\"] = md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9614dc8",
   "metadata": {},
   "source": [
    "# Define the hypermodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3f35aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, MaxPooling2D, LSTM, TimeDistributed, InputLayer, Reshape, BatchNormalization, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01dd69af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    evaluate model on test set and show results in dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    model : keras model\n",
    "        trained keras model.\n",
    "    X_test : numpy array\n",
    "        Features of holdout set.\n",
    "    y_test : numpy array\n",
    "        Labels of holdout set.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    display_df : DataFrame\n",
    "        Pandas dataframe containing evaluation results.\n",
    "    \"\"\"\n",
    "    eval_dict = model.evaluate(X_test, y_test, return_dict=True)\n",
    "    \n",
    "    display_df = pd.DataFrame([eval_dict.values()], columns=[list(eval_dict.keys())])\n",
    "    \n",
    "    return display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2ec1275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_m(hp):\n",
    "    # Define hyper model architecture\n",
    "    m = Sequential([\n",
    "        InputLayer(input_shape=(261,128,1)),\n",
    "        Reshape((9,29,128,1)),\n",
    "        TimeDistributed(Conv2D(16, kernel_size=(5,5), activation='relu')),\n",
    "        TimeDistributed(BatchNormalization()),\n",
    "        TimeDistributed(MaxPooling2D(pool_size=(4,4), strides=2)),\n",
    "\n",
    "        TimeDistributed(Conv2D(32, kernel_size=(3,3), activation='relu')),\n",
    "        TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=2)),\n",
    "\n",
    "        TimeDistributed(Conv2D(64, kernel_size=(3,3), activation='relu')),\n",
    "        TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=1)),\n",
    "        TimeDistributed(Flatten()),\n",
    "        \n",
    "        # Tune dropout layer with values in 0 - 0.6 with stepsize of 0.3\n",
    "        Dropout(hp.Float(\"dropout\", min_value=0, max_value=0.6, step=0.3)),\n",
    "        \n",
    "        # Tune number of units (2 - 3 - 4 - 5) and dropout (alues in 0 - 0.4 with stepsize of 0.2)\n",
    "        Bidirectional(LSTM(hp.Int(\"lstm_units\", min_value=2, max_value=5, step=1),\n",
    "                           dropout=hp.Float(\"lstm_dropout\", min_value=0, max_value=0.4, step=0.2),\n",
    "                           return_sequences=False)),\n",
    "        Dense(5, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Tune learning rate for Adam optimizer with values from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n",
    "    \n",
    "    # Define optimizer, loss, and metrics\n",
    "    m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[\"accuracy\"])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1313c3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        # Define hyper model architecture\n",
    "        m = Sequential([\n",
    "            InputLayer(input_shape=(261,128,1)),\n",
    "            Reshape((9,29,128,1)),\n",
    "            TimeDistributed(Conv2D(16, kernel_size=(5,5), activation='relu')),\n",
    "            TimeDistributed(BatchNormalization()),\n",
    "            TimeDistributed(MaxPooling2D(pool_size=(4,4), strides=2)),\n",
    "\n",
    "            TimeDistributed(Conv2D(32, kernel_size=(3,3), activation='relu')),\n",
    "            TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=2)),\n",
    "\n",
    "            TimeDistributed(Conv2D(64, kernel_size=(3,3), activation='relu')),\n",
    "            TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=1)),\n",
    "            TimeDistributed(Flatten()),\n",
    "\n",
    "            # Tune dropout layer with values in 0 - 0.6 with stepsize of 0.3\n",
    "            Dropout(hp.Float(\"dropout\", min_value=0, max_value=0.6, step=0.3)),\n",
    "\n",
    "            # Tune number of units (2 - 3 - 4 - 5) and dropout (alues in 0 - 0.4 with stepsize of 0.2)\n",
    "            Bidirectional(LSTM(hp.Int(\"lstm_units\", min_value=2, max_value=5, step=1),\n",
    "                               dropout=hp.Float(\"lstm_dropout\", min_value=0, max_value=0.4, step=0.2),\n",
    "                               return_sequences=False)),\n",
    "            Dense(5, activation='softmax')\n",
    "        ])\n",
    "\n",
    "        # Tune learning rate for Adam optimizer with values from 0.01, 0.001, or 0.0001\n",
    "        hp_learning_rate = hp.Choice(\"learning_rate\", values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "        # Define optimizer, loss, and metrics\n",
    "        m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=[\"accuracy\"])\n",
    "        return m\n",
    "\n",
    "    def fit(self, hp, model, *args, **kwargs):\n",
    "        return model.fit(\n",
    "            *args,\n",
    "            batch_size=hp.Choice(\"batch_size\", values=[8, 16, 32, 64, 128])\n",
    "            **kwargs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cf23690f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTuner(kt.tuners.Hyperband):\n",
    "      def run_trial(self, trial, *args, **kwargs):\n",
    "        # You can add additional HyperParameters for preprocessing and custom training loops via overriding `run_trial`\n",
    "        kwargs['batch_size'] = trial.hyperparameters.Choice(\"batch_size\", values=[8, 16, 32, 64, 128])\n",
    "        return super(MyTuner, self).run_trial(trial, *args, **kwargs)# Uses same arguments as the BayesianOptimization Tuner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14835cf",
   "metadata": {},
   "source": [
    "# Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b18f3a7",
   "metadata": {},
   "source": [
    "Get train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d647052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train = {}\n",
    "test = {}\n",
    "for d in datasets:\n",
    "    train[d] = {}\n",
    "    test[d] = {}\n",
    "    train_df, test_df = train_test_split(data[d]['metadata'], \n",
    "                                       test_size = 0.15, \n",
    "                                       random_state = 1938,\n",
    "                                       stratify = data[d]['metadata']['label'])\n",
    "    train_index = train_df.index\n",
    "    test_index = test_df.index\n",
    "    train[d]['x'] = data[d]['x'][train_index]\n",
    "    train[d]['y'] = data[d]['y'][train_index]\n",
    "    test[d]['x']= data[d]['x'][test_index]\n",
    "    test[d]['y']= data[d]['y'][test_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4d0ca86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3745, 5), (3183, 5), (562, 5))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['emodb']['y'].shape, train['emodb']['y'].shape, test['emodb']['y'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ed1e45",
   "metadata": {},
   "source": [
    "Select Hyperband tuner and initalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4e93339a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "dropout (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.6, 'step': 0.3, 'sampling': None}\n",
      "lstm_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 5, 'step': 1, 'sampling': None}\n",
      "lstm_dropout (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.4, 'step': 0.2, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(get_m,\n",
    "                     objective=\"val_loss\",\n",
    "                     max_epochs=100,\n",
    "                     # total number of trials to run during the search with different hyperparameter values\n",
    "                     # max_trials=3,\n",
    "                     # number of models that should be built and fit for each trial with the same hyperparameter values\n",
    "                     executions_per_trial=2,\n",
    "                     # the reduction factor for the number of epochs and number of models for each bracket\n",
    "                     factor=3,\n",
    "                     # the number of times to iterate over the full Hyperband algorithm\n",
    "                     hyperband_iterations=10,\n",
    "                     overwrite=True,\n",
    "                     directory=\"/datasets/nicolas_facchinetti/kt_dir\",\n",
    "                     project_name=\"cnnlstm\")\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "23604893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 0\n"
     ]
    }
   ],
   "source": [
    "# instantiate the tuner\n",
    "tuner = kt.Hyperband(MyHyperModel,\n",
    "                     objective=\"val_loss\",\n",
    "                     max_epochs=100,\n",
    "                     # total number of trials to run during the search with different hyperparameter values\n",
    "                     # max_trials=3,\n",
    "                     # number of models that should be built and fit for each trial with the same hyperparameter values\n",
    "                     executions_per_trial=2,\n",
    "                     # the reduction factor for the number of epochs and number of models for each bracket\n",
    "                     factor=3,\n",
    "                     # the number of times to iterate over the full Hyperband algorithm\n",
    "                     hyperband_iterations=10,\n",
    "                     overwrite=True,\n",
    "                     directory=\"/datasets/nicolas_facchinetti/kt_dir\",\n",
    "                     project_name=\"cnnlstm\")\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "57687c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "dropout (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.6, 'step': 0.3, 'sampling': None}\n",
      "lstm_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 5, 'step': 1, 'sampling': None}\n",
      "lstm_dropout (Float)\n",
      "{'default': 0.0, 'conditions': [], 'min_value': 0.0, 'max_value': 0.4, 'step': 0.2, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "# instantiate the tuner\n",
    "tuner = MyTuner(get_m,\n",
    "                objective=\"val_loss\",\n",
    "                max_epochs=1000,\n",
    "                # total number of trials to run during the search with different hyperparameter values\n",
    "                # max_trials=3,\n",
    "                # number of models that should be built and fit for each trial with the same hyperparameter values\n",
    "                executions_per_trial=2,\n",
    "                # the reduction factor for the number of epochs and number of models for each bracket\n",
    "                factor=2,\n",
    "                # the number of times to iterate over the full Hyperband algorithm\n",
    "                hyperband_iterations=10,\n",
    "                overwrite=True,\n",
    "                directory=\"/datasets/nicolas_facchinetti/kt_dir\",\n",
    "                project_name=\"cnnlstm\")\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4b33a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cf314325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 353 Complete [00h 00m 12s]\n",
      "val_loss: 1.6034173369407654\n",
      "\n",
      "Best val_loss So Far: 1.1538488864898682\n",
      "Total elapsed time: 01h 20m 09s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min', restore_best_weights=True)\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=6, verbose=0, min_delta=1e-4, mode='min')\n",
    "\n",
    "tuner.search(train['emodb']['x'], train['emodb']['y'],\n",
    "             epochs=100,\n",
    "             validation_split=0.2,\n",
    "             callbacks=[earlyStopping, reduce_lr_loss],\n",
    "             verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3ef8d689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in /datasets/nicolas_facchinetti/kt_dir/cnnlstm\n",
      "Showing 10 best trials\n",
      "<keras_tuner.engine.objective.Objective object at 0x7fc3f032ff40>\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.0\n",
      "lstm_units: 4\n",
      "lstm_dropout: 0.2\n",
      "learning_rate: 0.0001\n",
      "batch_size: 8\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 9\n",
      "tuner/round: 0\n",
      "Score: 1.1538488864898682\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.3\n",
      "lstm_units: 4\n",
      "lstm_dropout: 0.4\n",
      "learning_rate: 0.0001\n",
      "batch_size: 8\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 9\n",
      "tuner/round: 0\n",
      "Score: 1.202318549156189\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.0\n",
      "lstm_units: 3\n",
      "lstm_dropout: 0.2\n",
      "learning_rate: 0.0001\n",
      "batch_size: 8\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 9\n",
      "tuner/round: 0\n",
      "Score: 1.2051946520805359\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.0\n",
      "lstm_units: 4\n",
      "lstm_dropout: 0.4\n",
      "learning_rate: 0.001\n",
      "batch_size: 16\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 9\n",
      "tuner/round: 0\n",
      "Score: 1.2085976600646973\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.0\n",
      "lstm_units: 5\n",
      "lstm_dropout: 0.2\n",
      "learning_rate: 0.0001\n",
      "batch_size: 8\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 9\n",
      "tuner/round: 0\n",
      "Score: 1.2086238265037537\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.3\n",
      "lstm_units: 5\n",
      "lstm_dropout: 0.2\n",
      "learning_rate: 0.0001\n",
      "batch_size: 8\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 9\n",
      "tuner/round: 0\n",
      "Score: 1.221437692642212\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.3\n",
      "lstm_units: 5\n",
      "lstm_dropout: 0.0\n",
      "learning_rate: 0.001\n",
      "batch_size: 32\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 9\n",
      "tuner/round: 0\n",
      "Score: 1.2325389385223389\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.3\n",
      "lstm_units: 4\n",
      "lstm_dropout: 0.0\n",
      "learning_rate: 0.0001\n",
      "batch_size: 16\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 9\n",
      "tuner/round: 0\n",
      "Score: 1.2384405732154846\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.0\n",
      "lstm_units: 5\n",
      "lstm_dropout: 0.0\n",
      "learning_rate: 0.001\n",
      "batch_size: 16\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 9\n",
      "tuner/round: 0\n",
      "Score: 1.2413073778152466\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "dropout: 0.0\n",
      "lstm_units: 4\n",
      "lstm_dropout: 0.2\n",
      "learning_rate: 0.0001\n",
      "batch_size: 16\n",
      "tuner/epochs: 2\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 9\n",
      "tuner/round: 0\n",
      "Score: 1.243040919303894\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f897ee0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 - 3s - loss: 1.5904 - accuracy: 0.2675 - val_loss: 1.5720 - val_accuracy: 0.3407\n",
      "Epoch 2/100\n",
      "80/80 - 1s - loss: 1.4821 - accuracy: 0.3653 - val_loss: 1.4589 - val_accuracy: 0.4176\n",
      "Epoch 3/100\n",
      "80/80 - 1s - loss: 1.3664 - accuracy: 0.4462 - val_loss: 1.3781 - val_accuracy: 0.4615\n",
      "Epoch 4/100\n",
      "80/80 - 1s - loss: 1.2855 - accuracy: 0.4973 - val_loss: 1.2818 - val_accuracy: 0.4961\n",
      "Epoch 5/100\n",
      "80/80 - 1s - loss: 1.2345 - accuracy: 0.5169 - val_loss: 1.2220 - val_accuracy: 0.5338\n",
      "Epoch 6/100\n",
      "80/80 - 1s - loss: 1.1871 - accuracy: 0.5440 - val_loss: 1.1745 - val_accuracy: 0.5290\n",
      "Epoch 7/100\n",
      "80/80 - 1s - loss: 1.1559 - accuracy: 0.5546 - val_loss: 1.1498 - val_accuracy: 0.5306\n",
      "Epoch 8/100\n",
      "80/80 - 1s - loss: 1.1242 - accuracy: 0.5829 - val_loss: 1.1043 - val_accuracy: 0.5824\n",
      "Epoch 9/100\n",
      "80/80 - 1s - loss: 1.0924 - accuracy: 0.5970 - val_loss: 1.0824 - val_accuracy: 0.6028\n",
      "Epoch 10/100\n",
      "80/80 - 1s - loss: 1.0667 - accuracy: 0.6080 - val_loss: 1.0642 - val_accuracy: 0.5777\n",
      "Epoch 11/100\n",
      "80/80 - 1s - loss: 1.0388 - accuracy: 0.6167 - val_loss: 1.0257 - val_accuracy: 0.6201\n",
      "Epoch 12/100\n",
      "80/80 - 1s - loss: 1.0192 - accuracy: 0.6312 - val_loss: 1.0222 - val_accuracy: 0.5981\n",
      "Epoch 13/100\n",
      "80/80 - 1s - loss: 0.9888 - accuracy: 0.6414 - val_loss: 0.9945 - val_accuracy: 0.6248\n",
      "Epoch 14/100\n",
      "80/80 - 1s - loss: 0.9675 - accuracy: 0.6512 - val_loss: 0.9807 - val_accuracy: 0.6264\n",
      "Epoch 15/100\n",
      "80/80 - 1s - loss: 0.9430 - accuracy: 0.6732 - val_loss: 0.9837 - val_accuracy: 0.6279\n",
      "Epoch 16/100\n",
      "80/80 - 1s - loss: 0.9193 - accuracy: 0.6764 - val_loss: 0.9128 - val_accuracy: 0.6782\n",
      "Epoch 17/100\n",
      "80/80 - 1s - loss: 0.8982 - accuracy: 0.6815 - val_loss: 0.9066 - val_accuracy: 0.6562\n",
      "Epoch 18/100\n",
      "80/80 - 1s - loss: 0.9026 - accuracy: 0.6819 - val_loss: 0.8863 - val_accuracy: 0.6719\n",
      "Epoch 19/100\n",
      "80/80 - 1s - loss: 0.8598 - accuracy: 0.7003 - val_loss: 0.9079 - val_accuracy: 0.6609\n",
      "Epoch 20/100\n",
      "80/80 - 1s - loss: 0.8348 - accuracy: 0.7125 - val_loss: 0.8819 - val_accuracy: 0.6656\n",
      "Epoch 21/100\n",
      "80/80 - 1s - loss: 0.8238 - accuracy: 0.7207 - val_loss: 0.8607 - val_accuracy: 0.6703\n",
      "Epoch 22/100\n",
      "80/80 - 1s - loss: 0.8120 - accuracy: 0.7278 - val_loss: 0.8463 - val_accuracy: 0.6970\n",
      "Epoch 23/100\n",
      "80/80 - 1s - loss: 0.7844 - accuracy: 0.7266 - val_loss: 0.8276 - val_accuracy: 0.7033\n",
      "Epoch 24/100\n",
      "80/80 - 1s - loss: 0.7676 - accuracy: 0.7435 - val_loss: 0.8139 - val_accuracy: 0.7159\n",
      "Epoch 25/100\n",
      "80/80 - 1s - loss: 0.7397 - accuracy: 0.7742 - val_loss: 0.8049 - val_accuracy: 0.7363\n",
      "Epoch 26/100\n",
      "80/80 - 1s - loss: 0.7438 - accuracy: 0.7565 - val_loss: 0.7951 - val_accuracy: 0.7347\n",
      "Epoch 27/100\n",
      "80/80 - 1s - loss: 0.7114 - accuracy: 0.7773 - val_loss: 0.7867 - val_accuracy: 0.7331\n",
      "Epoch 28/100\n",
      "80/80 - 1s - loss: 0.7017 - accuracy: 0.7793 - val_loss: 0.8100 - val_accuracy: 0.7033\n",
      "Epoch 29/100\n",
      "80/80 - 1s - loss: 0.6967 - accuracy: 0.7808 - val_loss: 0.7604 - val_accuracy: 0.7441\n",
      "Epoch 30/100\n",
      "80/80 - 1s - loss: 0.6738 - accuracy: 0.7883 - val_loss: 0.7764 - val_accuracy: 0.7174\n",
      "Epoch 31/100\n",
      "80/80 - 1s - loss: 0.6630 - accuracy: 0.7985 - val_loss: 0.7502 - val_accuracy: 0.7520\n",
      "Epoch 32/100\n",
      "80/80 - 1s - loss: 0.6570 - accuracy: 0.7930 - val_loss: 0.7542 - val_accuracy: 0.7347\n",
      "Epoch 33/100\n",
      "80/80 - 1s - loss: 0.6460 - accuracy: 0.8028 - val_loss: 0.7407 - val_accuracy: 0.7253\n",
      "Epoch 34/100\n",
      "80/80 - 1s - loss: 0.6195 - accuracy: 0.8134 - val_loss: 0.7391 - val_accuracy: 0.7520\n",
      "Epoch 35/100\n",
      "80/80 - 1s - loss: 0.6121 - accuracy: 0.8166 - val_loss: 0.7298 - val_accuracy: 0.7300\n",
      "Epoch 36/100\n",
      "80/80 - 1s - loss: 0.6020 - accuracy: 0.8158 - val_loss: 0.7085 - val_accuracy: 0.7661\n",
      "Epoch 37/100\n",
      "80/80 - 1s - loss: 0.5813 - accuracy: 0.8272 - val_loss: 0.7076 - val_accuracy: 0.7582\n",
      "Epoch 38/100\n",
      "80/80 - 1s - loss: 0.5606 - accuracy: 0.8401 - val_loss: 0.7321 - val_accuracy: 0.7331\n",
      "Epoch 39/100\n",
      "80/80 - 1s - loss: 0.5613 - accuracy: 0.8425 - val_loss: 0.7096 - val_accuracy: 0.7614\n",
      "Epoch 40/100\n",
      "80/80 - 1s - loss: 0.5553 - accuracy: 0.8366 - val_loss: 0.6818 - val_accuracy: 0.7692\n",
      "Epoch 41/100\n",
      "80/80 - 1s - loss: 0.5414 - accuracy: 0.8488 - val_loss: 0.7109 - val_accuracy: 0.7614\n",
      "Epoch 42/100\n",
      "80/80 - 1s - loss: 0.5215 - accuracy: 0.8500 - val_loss: 0.6705 - val_accuracy: 0.7692\n",
      "Epoch 43/100\n",
      "80/80 - 1s - loss: 0.5074 - accuracy: 0.8610 - val_loss: 0.6888 - val_accuracy: 0.7677\n",
      "Epoch 44/100\n",
      "80/80 - 1s - loss: 0.5142 - accuracy: 0.8543 - val_loss: 0.6882 - val_accuracy: 0.7677\n",
      "Epoch 45/100\n",
      "80/80 - 1s - loss: 0.4958 - accuracy: 0.8665 - val_loss: 0.6721 - val_accuracy: 0.7614\n",
      "Epoch 46/100\n",
      "80/80 - 1s - loss: 0.4821 - accuracy: 0.8665 - val_loss: 0.6878 - val_accuracy: 0.7535\n",
      "Epoch 47/100\n",
      "80/80 - 1s - loss: 0.4706 - accuracy: 0.8798 - val_loss: 0.6545 - val_accuracy: 0.7614\n",
      "Epoch 48/100\n",
      "80/80 - 1s - loss: 0.4714 - accuracy: 0.8735 - val_loss: 0.6531 - val_accuracy: 0.7692\n",
      "Epoch 49/100\n",
      "80/80 - 1s - loss: 0.4548 - accuracy: 0.8794 - val_loss: 0.6505 - val_accuracy: 0.7771\n",
      "Epoch 50/100\n",
      "80/80 - 1s - loss: 0.4512 - accuracy: 0.8763 - val_loss: 0.6361 - val_accuracy: 0.7849\n",
      "Epoch 51/100\n",
      "80/80 - 1s - loss: 0.4332 - accuracy: 0.8845 - val_loss: 0.6351 - val_accuracy: 0.7739\n",
      "Epoch 52/100\n",
      "80/80 - 1s - loss: 0.4214 - accuracy: 0.8943 - val_loss: 0.6436 - val_accuracy: 0.7849\n",
      "Epoch 53/100\n",
      "80/80 - 1s - loss: 0.4067 - accuracy: 0.9014 - val_loss: 0.6294 - val_accuracy: 0.7771\n",
      "Epoch 54/100\n",
      "80/80 - 1s - loss: 0.4148 - accuracy: 0.8920 - val_loss: 0.6135 - val_accuracy: 0.7896\n",
      "Epoch 55/100\n",
      "80/80 - 1s - loss: 0.3944 - accuracy: 0.9077 - val_loss: 0.6427 - val_accuracy: 0.7645\n",
      "Epoch 56/100\n",
      "80/80 - 1s - loss: 0.3935 - accuracy: 0.9049 - val_loss: 0.6258 - val_accuracy: 0.7865\n",
      "Epoch 57/100\n",
      "80/80 - 1s - loss: 0.3829 - accuracy: 0.9077 - val_loss: 0.6299 - val_accuracy: 0.7630\n",
      "Epoch 58/100\n",
      "80/80 - 1s - loss: 0.3696 - accuracy: 0.9171 - val_loss: 0.6052 - val_accuracy: 0.7928\n",
      "Epoch 59/100\n",
      "80/80 - 1s - loss: 0.3665 - accuracy: 0.9124 - val_loss: 0.6085 - val_accuracy: 0.7849\n",
      "Epoch 60/100\n",
      "80/80 - 1s - loss: 0.3573 - accuracy: 0.9152 - val_loss: 0.6167 - val_accuracy: 0.7724\n",
      "Epoch 61/100\n",
      "80/80 - 1s - loss: 0.3423 - accuracy: 0.9214 - val_loss: 0.6239 - val_accuracy: 0.7896\n",
      "Epoch 62/100\n",
      "80/80 - 1s - loss: 0.3404 - accuracy: 0.9167 - val_loss: 0.6115 - val_accuracy: 0.7975\n",
      "Epoch 63/100\n",
      "80/80 - 1s - loss: 0.3319 - accuracy: 0.9246 - val_loss: 0.5948 - val_accuracy: 0.7959\n",
      "Epoch 64/100\n",
      "80/80 - 1s - loss: 0.3257 - accuracy: 0.9230 - val_loss: 0.6180 - val_accuracy: 0.7755\n",
      "Epoch 65/100\n",
      "80/80 - 1s - loss: 0.3202 - accuracy: 0.9305 - val_loss: 0.5980 - val_accuracy: 0.7881\n",
      "Epoch 66/100\n",
      "80/80 - 1s - loss: 0.3131 - accuracy: 0.9262 - val_loss: 0.5973 - val_accuracy: 0.7912\n",
      "Epoch 67/100\n",
      "80/80 - 1s - loss: 0.2986 - accuracy: 0.9340 - val_loss: 0.5863 - val_accuracy: 0.7928\n",
      "Epoch 68/100\n",
      "80/80 - 1s - loss: 0.3025 - accuracy: 0.9309 - val_loss: 0.5772 - val_accuracy: 0.7991\n",
      "Epoch 69/100\n",
      "80/80 - 1s - loss: 0.2872 - accuracy: 0.9348 - val_loss: 0.5848 - val_accuracy: 0.7928\n",
      "Epoch 70/100\n",
      "80/80 - 1s - loss: 0.2737 - accuracy: 0.9411 - val_loss: 0.5774 - val_accuracy: 0.7943\n",
      "Epoch 71/100\n",
      "80/80 - 1s - loss: 0.2745 - accuracy: 0.9427 - val_loss: 0.5761 - val_accuracy: 0.7943\n",
      "Epoch 72/100\n",
      "80/80 - 1s - loss: 0.2696 - accuracy: 0.9454 - val_loss: 0.5807 - val_accuracy: 0.7881\n",
      "Epoch 73/100\n",
      "80/80 - 1s - loss: 0.2626 - accuracy: 0.9442 - val_loss: 0.5872 - val_accuracy: 0.7849\n",
      "Epoch 74/100\n",
      "80/80 - 1s - loss: 0.2605 - accuracy: 0.9501 - val_loss: 0.5996 - val_accuracy: 0.7991\n",
      "Epoch 75/100\n",
      "80/80 - 1s - loss: 0.2558 - accuracy: 0.9478 - val_loss: 0.5750 - val_accuracy: 0.7975\n",
      "Epoch 76/100\n",
      "80/80 - 1s - loss: 0.2506 - accuracy: 0.9513 - val_loss: 0.5855 - val_accuracy: 0.7865\n",
      "Epoch 77/100\n",
      "80/80 - 1s - loss: 0.2448 - accuracy: 0.9474 - val_loss: 0.5603 - val_accuracy: 0.7991\n",
      "Epoch 78/100\n",
      "80/80 - 1s - loss: 0.2328 - accuracy: 0.9595 - val_loss: 0.5642 - val_accuracy: 0.8100\n",
      "Epoch 79/100\n",
      "80/80 - 1s - loss: 0.2200 - accuracy: 0.9627 - val_loss: 0.5539 - val_accuracy: 0.8038\n",
      "Epoch 80/100\n",
      "80/80 - 1s - loss: 0.2170 - accuracy: 0.9635 - val_loss: 0.5631 - val_accuracy: 0.7959\n",
      "Epoch 81/100\n",
      "80/80 - 1s - loss: 0.2125 - accuracy: 0.9595 - val_loss: 0.5555 - val_accuracy: 0.8053\n",
      "Epoch 82/100\n",
      "80/80 - 1s - loss: 0.2107 - accuracy: 0.9639 - val_loss: 0.5504 - val_accuracy: 0.8006\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80/80 - 1s - loss: 0.2043 - accuracy: 0.9635 - val_loss: 0.5550 - val_accuracy: 0.7991\n",
      "Epoch 84/100\n",
      "80/80 - 1s - loss: 0.2018 - accuracy: 0.9627 - val_loss: 0.5537 - val_accuracy: 0.8053\n",
      "Epoch 85/100\n",
      "80/80 - 1s - loss: 0.1925 - accuracy: 0.9682 - val_loss: 0.5471 - val_accuracy: 0.8085\n",
      "Epoch 86/100\n",
      "80/80 - 1s - loss: 0.1900 - accuracy: 0.9682 - val_loss: 0.5423 - val_accuracy: 0.8100\n",
      "Epoch 87/100\n",
      "80/80 - 1s - loss: 0.1870 - accuracy: 0.9713 - val_loss: 0.5369 - val_accuracy: 0.8100\n",
      "Epoch 88/100\n",
      "80/80 - 1s - loss: 0.1746 - accuracy: 0.9737 - val_loss: 0.5498 - val_accuracy: 0.8022\n",
      "Epoch 89/100\n",
      "80/80 - 1s - loss: 0.1828 - accuracy: 0.9705 - val_loss: 0.5543 - val_accuracy: 0.8038\n",
      "Epoch 90/100\n",
      "80/80 - 1s - loss: 0.1740 - accuracy: 0.9713 - val_loss: 0.5485 - val_accuracy: 0.8132\n",
      "Epoch 91/100\n",
      "80/80 - 1s - loss: 0.1727 - accuracy: 0.9705 - val_loss: 0.5553 - val_accuracy: 0.8100\n",
      "Epoch 92/100\n",
      "80/80 - 1s - loss: 0.1800 - accuracy: 0.9658 - val_loss: 0.5589 - val_accuracy: 0.7991\n",
      "Epoch 93/100\n",
      "80/80 - 1s - loss: 0.1607 - accuracy: 0.9780 - val_loss: 0.5322 - val_accuracy: 0.8132\n",
      "Epoch 94/100\n",
      "80/80 - 1s - loss: 0.1576 - accuracy: 0.9760 - val_loss: 0.5437 - val_accuracy: 0.8163\n",
      "Epoch 95/100\n",
      "80/80 - 1s - loss: 0.1627 - accuracy: 0.9713 - val_loss: 0.5210 - val_accuracy: 0.8163\n",
      "Epoch 96/100\n",
      "80/80 - 1s - loss: 0.1562 - accuracy: 0.9741 - val_loss: 0.5328 - val_accuracy: 0.7975\n",
      "Epoch 97/100\n",
      "80/80 - 1s - loss: 0.1509 - accuracy: 0.9749 - val_loss: 0.5247 - val_accuracy: 0.8179\n",
      "Epoch 98/100\n",
      "80/80 - 1s - loss: 0.1402 - accuracy: 0.9808 - val_loss: 0.5483 - val_accuracy: 0.8100\n",
      "Epoch 99/100\n",
      "80/80 - 1s - loss: 0.1401 - accuracy: 0.9800 - val_loss: 0.5348 - val_accuracy: 0.8085\n",
      "Epoch 100/100\n",
      "80/80 - 1s - loss: 0.1366 - accuracy: 0.9808 - val_loss: 0.5348 - val_accuracy: 0.8100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc3cc187ee0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the optimal hyperparameters from the results\n",
    "best_hps=tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Build model\n",
    "h_model = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=6, verbose=1, min_delta=1e-4, mode='min')\n",
    "\n",
    "# Train the hypertuned model\n",
    "h_model.fit(train['emodb']['x'], train['emodb']['y'], epochs=100, validation_split=0.2, callbacks=[earlyStopping, reduce_lr_loss], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4d34bbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5570 - accuracy: 0.7989\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hypertuned</th>\n",
       "      <td>0.556999</td>\n",
       "      <td>0.798932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                loss  accuracy\n",
       "Hypertuned  0.556999  0.798932"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "# Evaluate model on test set\n",
    "hyper_df = evaluate_model(h_model, test['emodb']['x'], test['emodb']['y'])\n",
    "\n",
    "# Set index to hypertuned\n",
    "hyper_df.index = [\"Hypertuned\"]\n",
    "\n",
    "# Append results in dataframe\n",
    "results.append(hyper_df)\n",
    "hyper_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b5ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461a6b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be5aa68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c8820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_model_opt():\n",
    "    new_model = tensorflow.keras.Sequential.from_config(chosen)\n",
    "    new_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return new_model\n",
    "    \n",
    "model = KerasClassifier(build_fn=create_model_opt, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f5069d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# define the grid search parameters\n",
    "batch_size = [16, 32, 64, 128]\n",
    "epochs = [30, 50, 70]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7386cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_opt = {}\n",
    "for d in data:\n",
    "    print(f'Dataset {d}')\n",
    "    \n",
    "    x = data[d][\"x\"]\n",
    "    y = data[d][\"y\"]\n",
    "    metadata = data[d][\"metadata\"]\n",
    "    cv = leave_one_speaker_out(metadata, n=3)\n",
    "    \n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, verbose=3)\n",
    "    grid_result = grid.fit(x, y)\n",
    "    results_opt[d] = grid_result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6d0846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "for d in results_opt:\n",
    "    print(d)\n",
    "    grid_result = results_opt[d]\n",
    "    print(\"\\tBest: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"\\t%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe7dfe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283496bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
