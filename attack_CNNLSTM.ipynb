{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3cd8df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 18:20:24.344094: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67789988",
   "metadata": {},
   "source": [
    "Load datasets and standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "522acb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dsname):\n",
    "    metadata = pd.read_csv(f\"/datasets/nicolas_facchinetti/processed_data/{dsname}/metadata_final.csv\")\n",
    "    x = pickle.load(open(f\"/datasets/nicolas_facchinetti/processed_data/{dsname}/processed_data0.p\", \"rb\" ))\n",
    "    y = pickle.load(open(f\"/datasets/nicolas_facchinetti/processed_data/{dsname}/processed_labels.p\", \"rb\" ))\n",
    "    return metadata, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c97d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "datasets = [\"emodb\"]\n",
    "scalers = {d: StandardScaler() for d in datasets}\n",
    "\n",
    "data = {}\n",
    "for d in datasets:\n",
    "    md, x, y = load_dataset(d)\n",
    "    data[d] = {}\n",
    "    # standardize data\n",
    "    n = x.shape\n",
    "    data[d][\"x\"] = scalers[d].fit_transform(x.reshape(n[0],-1)).reshape(n)\n",
    "    data[d][\"y\"] = y\n",
    "    data[d][\"metadata\"] = md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b18f3a7",
   "metadata": {},
   "source": [
    "Get train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d647052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train = {}\n",
    "test = {}\n",
    "for d in datasets:\n",
    "    train[d] = {}\n",
    "    test[d] = {}\n",
    "    train_df, test_df = train_test_split(data[d]['metadata'], \n",
    "                                       test_size = 0.2, \n",
    "                                       random_state = 1938,\n",
    "                                       stratify = data[d]['metadata']['label'])\n",
    "    train_index = train_df.index\n",
    "    test_index = test_df.index\n",
    "    train[d]['x'] = data[d]['x'][train_index]\n",
    "    train[d]['y'] = data[d]['y'][train_index]\n",
    "    test[d]['x']= data[d]['x'][test_index]\n",
    "    test[d]['y']= data[d]['y'][test_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4d0ca86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4181, 5), (3344, 5), (837, 5))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['emodb']['y'].shape, train['emodb']['y'].shape, test['emodb']['y'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e118a",
   "metadata": {},
   "source": [
    "Load best parameter for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d19b5071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'emodb': {'dropout': 0.3,\n",
       "  'lstm_dropout': 0.2,\n",
       "  'learning_rate': 0.001,\n",
       "  'batch_size': 32,\n",
       "  'tuner/epochs': 120,\n",
       "  'tuner/initial_epoch': 8,\n",
       "  'tuner/bracket': 1,\n",
       "  'tuner/round': 1,\n",
       "  'tuner/trial_id': '0050',\n",
       "  'lstm_units': 2},\n",
       " 'emovo': {'dropout': 0.3,\n",
       "  'lstm_dropout': 0.0,\n",
       "  'learning_rate': 0.0001,\n",
       "  'batch_size': 8,\n",
       "  'tuner/epochs': 120,\n",
       "  'tuner/initial_epoch': 8,\n",
       "  'tuner/bracket': 1,\n",
       "  'tuner/round': 1,\n",
       "  'tuner/trial_id': '0001',\n",
       "  'lstm_units': 2},\n",
       " 'ravdess': {'dropout': 0.6,\n",
       "  'lstm_dropout': 0.2,\n",
       "  'learning_rate': 0.001,\n",
       "  'batch_size': 128,\n",
       "  'tuner/epochs': 120,\n",
       "  'tuner/initial_epoch': 0,\n",
       "  'tuner/bracket': 0,\n",
       "  'tuner/round': 0,\n",
       "  'lstm_units': 2}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras_tuner as kt\n",
    "param = pickle.load(open('/datasets/nicolas_facchinetti/param.p', \"rb\" ))\n",
    "param  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df04cc7",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd235186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Dropout, MaxPooling2D, LSTM, TimeDistributed, InputLayer, Reshape, BatchNormalization, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a90f0fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_m(best_param):\n",
    "    # Define hyper model architecture\n",
    "    m = Sequential([\n",
    "        InputLayer(input_shape=(261,128,1)),\n",
    "        Reshape((9,29,128,1)),\n",
    "        TimeDistributed(Conv2D(16, kernel_size=(5,5), activation='relu')),\n",
    "        TimeDistributed(BatchNormalization()),\n",
    "        TimeDistributed(MaxPooling2D(pool_size=(4,4), strides=2)),\n",
    "\n",
    "        TimeDistributed(Conv2D(32, kernel_size=(3,3), activation='relu')),\n",
    "        TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=2)),\n",
    "\n",
    "        TimeDistributed(Conv2D(64, kernel_size=(3,3), activation='relu')),\n",
    "        TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=1)),\n",
    "        TimeDistributed(Flatten()),\n",
    "        \n",
    "        Dropout(best_param['dropout']),\n",
    "        \n",
    "        Bidirectional(LSTM(256, dropout=best_param['lstm_dropout'], return_sequences=False)),\n",
    "        Dense(5, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    lr = best_param['learning_rate']\n",
    "    \n",
    "    # Define optimizer, loss, and metrics\n",
    "    m.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=[\"accuracy\"])\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b75536d",
   "metadata": {},
   "source": [
    "Models training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48f97ba0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 18:20:27.413951: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-19 18:20:27.415332: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-01-19 18:20:27.562959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:15:00.0 name: NVIDIA TITAN V computeCapability: 7.0\n",
      "coreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.77GiB deviceMemoryBandwidth: 607.97GiB/s\n",
      "2023-01-19 18:20:27.562995: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-01-19 18:20:27.564942: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-01-19 18:20:27.565037: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-01-19 18:20:27.566763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-19 18:20:27.567114: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-19 18:20:27.568822: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-01-19 18:20:27.569698: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-01-19 18:20:27.573072: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-01-19 18:20:27.576379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-01-19 18:20:27.576805: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-19 18:20:27.578048: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-01-19 18:20:27.578316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:15:00.0 name: NVIDIA TITAN V computeCapability: 7.0\n",
      "coreClock: 1.455GHz coreCount: 80 deviceMemorySize: 11.77GiB deviceMemoryBandwidth: 607.97GiB/s\n",
      "2023-01-19 18:20:27.578338: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-01-19 18:20:27.578360: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-01-19 18:20:27.578368: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-01-19 18:20:27.578377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-01-19 18:20:27.578386: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-01-19 18:20:27.578394: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-01-19 18:20:27.578402: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-01-19 18:20:27.578411: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-01-19 18:20:27.578744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2023-01-19 18:20:27.578772: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-01-19 18:20:28.120392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2023-01-19 18:20:28.120421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2023-01-19 18:20:28.120427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2023-01-19 18:20:28.121164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10904 MB memory) -> physical GPU (device: 0, name: NVIDIA TITAN V, pci bus id: 0000:15:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on emodb dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 18:20:28.822705: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-01-19 18:20:28.837891: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3301490000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-19 18:20:30.609941: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-01-19 18:20:30.795494: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84/84 - 5s - loss: 1.2364 - accuracy: 0.4968 - val_loss: 2.3020 - val_accuracy: 0.2706\n",
      "Epoch 2/100\n",
      "84/84 - 1s - loss: 0.7368 - accuracy: 0.7107 - val_loss: 1.2075 - val_accuracy: 0.5755\n",
      "Epoch 3/100\n",
      "84/84 - 1s - loss: 0.5353 - accuracy: 0.7989 - val_loss: 0.8006 - val_accuracy: 0.6816\n",
      "Epoch 4/100\n",
      "84/84 - 1s - loss: 0.3829 - accuracy: 0.8665 - val_loss: 0.5280 - val_accuracy: 0.7952\n",
      "Epoch 5/100\n",
      "84/84 - 1s - loss: 0.2867 - accuracy: 0.9002 - val_loss: 0.4139 - val_accuracy: 0.8371\n",
      "Epoch 6/100\n",
      "84/84 - 1s - loss: 0.2096 - accuracy: 0.9271 - val_loss: 0.3728 - val_accuracy: 0.8550\n",
      "Epoch 7/100\n",
      "84/84 - 1s - loss: 0.1875 - accuracy: 0.9376 - val_loss: 0.3299 - val_accuracy: 0.8714\n",
      "Epoch 8/100\n",
      "84/84 - 1s - loss: 0.1275 - accuracy: 0.9622 - val_loss: 0.3220 - val_accuracy: 0.8685\n",
      "Epoch 9/100\n",
      "84/84 - 1s - loss: 0.0850 - accuracy: 0.9802 - val_loss: 0.2602 - val_accuracy: 0.9013\n",
      "Epoch 10/100\n",
      "84/84 - 1s - loss: 0.0664 - accuracy: 0.9806 - val_loss: 0.2627 - val_accuracy: 0.9088\n",
      "Epoch 11/100\n",
      "84/84 - 1s - loss: 0.0501 - accuracy: 0.9865 - val_loss: 0.2572 - val_accuracy: 0.9058\n",
      "Epoch 12/100\n",
      "84/84 - 1s - loss: 0.0380 - accuracy: 0.9936 - val_loss: 0.2647 - val_accuracy: 0.9043\n",
      "Epoch 13/100\n",
      "84/84 - 1s - loss: 0.0324 - accuracy: 0.9944 - val_loss: 0.2677 - val_accuracy: 0.8984\n",
      "Epoch 14/100\n",
      "84/84 - 1s - loss: 0.0308 - accuracy: 0.9940 - val_loss: 0.3191 - val_accuracy: 0.8819\n",
      "Epoch 15/100\n",
      "84/84 - 1s - loss: 0.0294 - accuracy: 0.9944 - val_loss: 0.2762 - val_accuracy: 0.8954\n",
      "Epoch 16/100\n",
      "84/84 - 1s - loss: 0.0225 - accuracy: 0.9944 - val_loss: 0.3174 - val_accuracy: 0.8909\n",
      "Epoch 17/100\n",
      "84/84 - 1s - loss: 0.0200 - accuracy: 0.9951 - val_loss: 0.2925 - val_accuracy: 0.9013\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 18/100\n",
      "84/84 - 1s - loss: 0.0095 - accuracy: 0.9989 - val_loss: 0.2670 - val_accuracy: 0.9073\n",
      "Epoch 19/100\n",
      "84/84 - 1s - loss: 0.0069 - accuracy: 0.9993 - val_loss: 0.2707 - val_accuracy: 0.9013\n",
      "Epoch 20/100\n",
      "84/84 - 1s - loss: 0.0052 - accuracy: 1.0000 - val_loss: 0.2665 - val_accuracy: 0.9043\n",
      "Epoch 21/100\n",
      "84/84 - 1s - loss: 0.0059 - accuracy: 0.9993 - val_loss: 0.2604 - val_accuracy: 0.9028\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Training on emovo dataset\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'emovo'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m reduce_lr_loss \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00md\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m dataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m history \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mfit(\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m], train[d][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     10\u001b[0m                 epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     11\u001b[0m                 batch_size\u001b[38;5;241m=\u001b[39mparam[d][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     12\u001b[0m                 validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,\n\u001b[1;32m     13\u001b[0m                 callbacks\u001b[38;5;241m=\u001b[39m[earlyStopping, reduce_lr_loss], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m models[d] \u001b[38;5;241m=\u001b[39m m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'emovo'"
     ]
    }
   ],
   "source": [
    "models = {}\n",
    "for d in param:\n",
    "    m = get_m(param[d])\n",
    "\n",
    "    earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1, mode='min', restore_best_weights=True)\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=6, verbose=1, min_delta=1e-4, mode='min')\n",
    "    \n",
    "    print(f'Training on {d} dataset')\n",
    "    history = m.fit(train[d]['x'], train[d]['y'],\n",
    "                    epochs=100,\n",
    "                    batch_size=param[d][\"batch_size\"],\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=[earlyStopping, reduce_lr_loss], verbose=2)\n",
    "    print(\"\\n\\n\\n\")\n",
    "    \n",
    "    models[d] = m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b413dc36",
   "metadata": {},
   "source": [
    "Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4a8fd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 7ms/step - loss: 0.3325 - accuracy: 0.8925\n",
      "For emodb test loss: 0.33246275782585144 accuracy: 0.8924731016159058\n"
     ]
    }
   ],
   "source": [
    "for d in models:\n",
    "    loss, accuracy = models[d].evaluate(test[d]['x'], test[d]['y'], batch_size=param[d][\"batch_size\"])\n",
    "    print(f'For {d} test loss: {loss} accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cfdfab",
   "metadata": {},
   "source": [
    "# Model attack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fb6cf7",
   "metadata": {},
   "source": [
    "Make ART model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00df425d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nicolas/.conda/envs/thesis/lib/python3.9/site-packages/art/estimators/certification/__init__.py:13: UserWarning: PyTorch not found. Not importing DeepZ functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ functionality\")\n"
     ]
    }
   ],
   "source": [
    "from art.estimators.classification import TensorFlowV2Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8837a76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 9, 29, 128, 1)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 9, 25, 124, 16)    416       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 9, 25, 124, 16)    64        \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 9, 11, 61, 16)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 9, 9, 59, 32)      4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 9, 4, 29, 32)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 9, 2, 27, 64)      18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 9, 1, 26, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_7 (TimeDist (None, 9, 1664)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 9, 1664)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 512)               3934208   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 2565      \n",
      "=================================================================\n",
      "Total params: 3,960,389\n",
      "Trainable params: 3,960,357\n",
      "Non-trainable params: 32\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "models['emodb'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb61026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {d: TensorFlowV2Classifier(models[d],\n",
    "                                         nb_classes=5,\n",
    "                                         input_shape=(261,128,1),\n",
    "                                         loss_object=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                                         channels_first=False)\n",
    "               for d in models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4c4a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from art.attacks.evasion import FastGradientMethod\n",
    "attack_fgsm = FastGradientMethod(estimator=classifiers['emodb'], eps=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6558c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_adv = attack_fgsm.generate(test['emodb']['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d6d79e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 6ms/step - loss: 5.4427 - accuracy: 0.1529\n",
      "For emodb test loss: 5.44273567199707 accuracy: 0.15292711555957794\n",
      "Average perturbation: 0.25\n"
     ]
    }
   ],
   "source": [
    "for d in models:\n",
    "    loss, accuracy = models[d].evaluate(x_test_adv, test[d]['y'], batch_size=param[d][\"batch_size\"])\n",
    "    perturbation = np.mean(np.abs((x_test_adv - test[d]['x'])))\n",
    "    print(f'For {d} test loss: {loss} accuracy: {accuracy}')\n",
    "    print('Average perturbation: {:4.2f}'.format(perturbation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77645e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3accbd03828b4f11a5907e0b601e3e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "C&W L_inf:   0%|          | 0/837 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from art.attacks.evasion import CarliniLInfMethod\n",
    "\n",
    "# tune LR, init and largest cost to reduce time\n",
    "attack_cw = CarliniLInfMethod(classifier=classifiers['emodb'],\n",
    "                              max_iter=10,\n",
    "                              learning_rate=0.01,\n",
    "                              initial_const=1e0,\n",
    "                              largest_const=2e0,\n",
    "                              verbose=True)\n",
    "\n",
    "x_test_adv = attack_cw.generate(test['emodb']['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1506b646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 6ms/step - loss: 2.4132 - accuracy: 0.0729\n",
      "For emodb test loss: 2.413248062133789 accuracy: 0.07287932932376862\n",
      "Average perturbation: 0.05\n"
     ]
    }
   ],
   "source": [
    "for d in models:\n",
    "    loss, accuracy = models[d].evaluate(x_test_adv, test[d]['y'], batch_size=param[d][\"batch_size\"])\n",
    "    perturbation = np.mean(np.abs((x_test_adv - test[d]['x'])))\n",
    "    print(f'For {d} test loss: {loss} accuracy: {accuracy}')\n",
    "    print('Average perturbation: {:4.2f}'.format(perturbation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7589dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
